{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/gulugulu/repos/PuningAnalysis/src')\n",
    "from simulation.WTS_class import SeqSimulate, generate_ancestor\n",
    "from scipy import stats\n",
    "from numpy.random import default_rng\n",
    "import numpy as np\n",
    "from cogent3.maths.matrix_exponential_integration import expected_number_subs\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_matrix = np.array([[-1.75025094,  0.94143256,  0.45306226,  0.35575611],\n",
    "       [ 0.49505807, -2.27893035,  0.88176788,  0.90210439],\n",
    "       [ 0.36411798,  0.18070926, -0.91594839,  0.37112115],\n",
    "       [ 0.77758124,  0.75396143,  0.52505328, -2.05659595]])\n",
    "\n",
    "Q_matrix2 = np.array([[-0.8913651590062768,\n",
    "  0.06758713003981928,\n",
    "  0.26750861021623484,\n",
    "  0.5562694187502226],\n",
    " [0.48766534934241146,\n",
    "  -1.1914228729789795,\n",
    "  0.2796236707498311,\n",
    "  0.42413385288673694],\n",
    " [0.48963798725695706,\n",
    "  0.6855172408178508,\n",
    "  -1.5509279536481513,\n",
    "  0.3757727255733433],\n",
    " [0.1537313911769212,\n",
    "  0.7977890102842006,\n",
    "  0.551525454894267,\n",
    "  -1.5030458563553888]])\n",
    "\n",
    "Q_matrix3 = np.array([[-1.4789149719418297,\n",
    "  0.2942056179993613,\n",
    "  0.5014501422645519,\n",
    "  0.6832592116779167],\n",
    " [0.7335649348307921,\n",
    "  -1.319277973081591,\n",
    "  0.19058964898276037,\n",
    "  0.39512338926803847],\n",
    " [0.02241627235342083,\n",
    "  0.2150187330048211,\n",
    "  -0.8805864461303382,\n",
    "  0.6431514407720963],\n",
    " [0.08026712260332504,\n",
    "  0.35104850742302635,\n",
    "  0.1772278959502105,\n",
    "  -0.6085435259765619]])\n",
    "\n",
    "n = 1000\n",
    "pi = [0.35, 0.15, 0.05, 0.45]\n",
    "pi2 = [0.1, 0.1, 0.1, 0.7]\n",
    "pi3 = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "repeats = [10, 50, 100, 200, 300, 500]\n",
    "time_range = [0.5, 1, 2, 3, 4]\n",
    "repeat = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator = SeqSimulate(Q_matrix, 1000, 100, 5, pi)\n",
    "# simulator.average_substitution(max_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwaiting_time_simulator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_substitution\n\u001b[1;32m      3\u001b[0m Q_dict  \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m: Q_matrix}\n\u001b[0;32m----> 5\u001b[0m original \u001b[38;5;241m=\u001b[39m \u001b[43maverage_substitution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/PuningAnalysis/src/simulation/waiting_time_simulator.py:309\u001b[0m, in \u001b[0;36maverage_substitution\u001b[0;34m(Q, t, repeats, length, pi, markov)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeats):\n\u001b[1;32m    308\u001b[0m     ancestor_sequence \u001b[38;5;241m=\u001b[39m generate_ancestor(length, pi)\n\u001b[0;32m--> 309\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mancestor_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkov\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    310\u001b[0m     ns_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(history)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    311\u001b[0m     ns_per_site \u001b[38;5;241m=\u001b[39m ns_total\u001b[38;5;241m/\u001b[39mn\n",
      "File \u001b[0;32m~/repos/PuningAnalysis/src/simulation/waiting_time_simulator.py:290\u001b[0m, in \u001b[0;36msimulate_seq\u001b[0;34m(ancestor_seq, max_time, rate_matrices_dict, markov_order)\u001b[0m\n\u001b[1;32m    288\u001b[0m new_base \u001b[38;5;241m=\u001b[39m min_position[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    289\u001b[0m substitution_time \u001b[38;5;241m=\u001b[39m min_time \n\u001b[0;32m--> 290\u001b[0m waiting_times, min_position, min_time \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_waiting_times\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDNA_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwaiting_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkov_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m DNA_seq[seq_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Substitue with new base in DNA sequence\u001b[39;00m\n\u001b[1;32m    292\u001b[0m history\u001b[38;5;241m.\u001b[39mappend(DNA_seq\u001b[38;5;241m.\u001b[39mcopy())\n",
      "File \u001b[0;32m~/repos/PuningAnalysis/src/simulation/waiting_time_simulator.py:257\u001b[0m, in \u001b[0;36mupdate_waiting_times\u001b[0;34m(DNA_seq, Q_dict, waiting_times, min_position, min_time, markov_order)\u001b[0m\n\u001b[1;32m    254\u001b[0m DNA_seq[seq_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Substitue with new base in DNA sequence \u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Regenerate all waiting times\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m waiting_times, min_position, min_time \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_waiting_times\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDNA_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkov_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m waiting_times, min_position, min_time\n",
      "File \u001b[0;32m~/repos/PuningAnalysis/src/simulation/waiting_time_simulator.py:192\u001b[0m, in \u001b[0;36minitialize_waiting_times\u001b[0;34m(DNA_seq, Q_dict, markov_order)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_base \u001b[38;5;241m!=\u001b[39m curr_base:\n\u001b[1;32m    191\u001b[0m     rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(Q_dict[curr_context][curr_base, next_base])\n\u001b[0;32m--> 192\u001b[0m     time \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexponential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     waiting_times[seq_index, next_base] \u001b[38;5;241m=\u001b[39m time\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time \u001b[38;5;241m<\u001b[39m min_time:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from simulation.waiting_time_simulator import average_substitution\n",
    "\n",
    "Q_dict  = {'0': Q_matrix}\n",
    "\n",
    "original = average_substitution(Q_dict, 1, 100, 1000, pi, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for different simulation time & sequence length\n",
    "### sequence length = 1000, repeat = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat = 200\n",
    "# results = {'1000': {}}\n",
    "# for time in time_range:\n",
    "#     simulator = SeqSimulate(Q_matrix, 1000, repeat, 11, pi)\n",
    "#     result = simulator.average_substitution(time)\n",
    "#     ns_per_site = result[0]\n",
    "#     avg_ns_per_site = result[1]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     results['1000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "# with open('../../../results/WTS_1000(2).json', 'w') as outfile:\n",
    "#     json.dump(results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat = 200\n",
    "# results2 = {'1000': {}}\n",
    "# simulator = SeqSimulate(Q_matrix, 1000, repeat, 5, pi)\n",
    "\n",
    "# for time in time_range:\n",
    "#     print(time)\n",
    "#     result = simulator.average_substitution(time)\n",
    "#     ns_per_site = result[0]\n",
    "#     avg_ns_per_site = result[1]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     results2['1000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "# with open('../../../results/WTS_1000(3).json', 'w') as outfile:\n",
    "#     json.dump(results2, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence length = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat = 200\n",
    "# results1 = {'2000': {}}\n",
    "# simulator = SeqSimulate(Q_matrix, 2000, repeat, 10, pi)\n",
    "\n",
    "# for time in time_range:\n",
    "#     print(time)\n",
    "#     result = simulator.average_substitution(time)\n",
    "#     ns_per_site = result[0]\n",
    "#     avg_ns_per_site = result[1]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     results1['2000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "# with open('../../../results/WTS_2000(1).json', 'w') as outfile:\n",
    "#     json.dump(results1, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repeat = 200\n",
    "# results2 = {'2000': {}}\n",
    "# simulator = SeqSimulate(Q_matrix, 2000, repeat, 11, pi)\n",
    "\n",
    "# for time in time_range:\n",
    "#     print(time)\n",
    "#     result = simulator.average_substitution(time)\n",
    "#     ns_per_site = result[0]\n",
    "#     avg_ns_per_site = result[1]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     results2['2000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "# with open('../../../results/WTS_2000(2).json', 'w') as outfile:\n",
    "#     json.dump(results2, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat = 200\n",
    "# results3 = {'2000': {}}\n",
    "# simulator = SeqSimulate(Q_matrix, 2000, repeat, 12, pi)\n",
    "\n",
    "# for time in time_range:\n",
    "#     print(time)\n",
    "#     result = simulator.average_substitution(time)\n",
    "#     ns_per_site = result[0]\n",
    "#     avg_ns_per_site = result[1]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     results3['2000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "# with open('../../../results/WTS_2000(3).json', 'w') as outfile:\n",
    "#     json.dump(results3, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence length = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 100\n",
    "results1 = {'3000': {}}\n",
    "simulator = SeqSimulate(Q_matrix, 3000, repeat, 10, pi)\n",
    "\n",
    "for time in time_range:\n",
    "    result = simulator.average_substitution(time)\n",
    "    ns_per_site = result[0]\n",
    "    avg_ns_per_site = result[1]\n",
    "    theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    results1['3000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "with open('../../../results/WTS_3000(1).json', 'w') as outfile:\n",
    "    json.dump(results1, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 100\n",
    "results2 = {'3000': {}}\n",
    "simulator = SeqSimulate(Q_matrix, 3000, repeat, 11, pi)\n",
    "\n",
    "for time in time_range:\n",
    "    print(time)\n",
    "    result = simulator.average_substitution(time)\n",
    "    ns_per_site = result[0]\n",
    "    avg_ns_per_site = result[1]\n",
    "    theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    results2['3000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "with open('../../../results/WTS_3000(2).json', 'w') as outfile:\n",
    "    json.dump(results2, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 100\n",
    "results3 = {'3000': {}}\n",
    "simulator = SeqSimulate(Q_matrix, 3000, repeat, 12, pi)\n",
    "\n",
    "for time in time_range:\n",
    "    print(time)\n",
    "    result = simulator.average_substitution(time)\n",
    "    ns_per_site = result[0]\n",
    "    avg_ns_per_site = result[1]\n",
    "    theoretical = expected_number_subs(pi, Q_matrix, time)\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    results3['3000'][time] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "\n",
    "with open('../../../results/WTS_3000(3).json', 'w') as outfile:\n",
    "    json.dump(results3, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for different repeat, length = 1000, time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # seed_seq = range(6)\n",
    "# # repeats = [10, 50, 100, 200, 300, 500]\n",
    "# # results = []\n",
    "# # for element in list(zip(seed_seq, repeats)):\n",
    "# #     seed, repeat = element\n",
    "# #     simulator = SeqSimulate(Q_matrix, 2000, repeat, seed, pi)\n",
    "# #     result = simulator.average_substitution(max_time = 1)\n",
    "# #     results.append(result)\n",
    "\n",
    "# # WTS_repeats_result = {}\n",
    "# # for i in range(len(results)):\n",
    "# #     ns_per_site, avg_ns_per_site = results[i]\n",
    "# #     theoretical = expected_number_subs(pi, Q_matrix, 1)\n",
    "# #     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "# #     WTS_repeats_result[repeats[i]] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "    \n",
    "\n",
    "# with open('../../../results/WTS_repeat.json', 'w') as outfile:\n",
    "#     json.dump(WTS_repeats_result, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_seq = [1 , 2, 3, 4, 5, 6]\n",
    "# repeats = [10, 50, 100, 200, 300, 500]\n",
    "# results1 = []\n",
    "# for element in list(zip(seed_seq, repeats)):\n",
    "#     seed, repeat = element\n",
    "#     simulator = SeqSimulate(Q_matrix, 2000, repeat, seed, pi)\n",
    "#     result = simulator.average_substitution(max_time = 1)\n",
    "#     results1.append(result)\n",
    "\n",
    "# WTS_repeats_result1 = {}\n",
    "# for i in range(len(results1)):\n",
    "#     ns_per_site, avg_ns_per_site = results1[i]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, 1)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     WTS_repeats_result1[repeats[i]] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "# with open('../../../results/WTS_repeat(1).json', 'w') as outfile:\n",
    "#     json.dump(WTS_repeats_result1, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_seq = [10, 11, 12, 13, 14, 15]\n",
    "# repeats = [10, 50, 100, 200, 300, 500]\n",
    "# results2 = []\n",
    "# for element in list(zip(seed_seq, repeats)):\n",
    "#     seed, repeat = element\n",
    "#     simulator = SeqSimulate(Q_matrix, 2000, repeat, seed, pi)\n",
    "#     result = simulator.average_substitution(max_time = 1)\n",
    "#     results2.append(result)\n",
    "\n",
    "# WTS_repeats_result2 = {}\n",
    "# for i in range(len(results2)):\n",
    "#     ns_per_site, avg_ns_per_site = results2[i]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, 1)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     WTS_repeats_result2[repeats[i]] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "# with open('../../../results/WTS_repeat(2).json', 'w') as outfile:\n",
    "#     json.dump(WTS_repeats_result2, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_seq = [20, 21, 22, 23, 24, 25]\n",
    "# repeats = [10, 50, 100, 200, 300, 500]\n",
    "# results3 = []\n",
    "# for element in list(zip(seed_seq, repeats)):\n",
    "#     seed, repeat = element\n",
    "#     simulator = SeqSimulate(Q_matrix, 2000, repeat, seed, pi)\n",
    "#     result = simulator.average_substitution(max_time = 1)\n",
    "#     results3.append(result)\n",
    "\n",
    "# WTS_repeats_result3 = {}\n",
    "# for i in range(len(results3)):\n",
    "#     ns_per_site, avg_ns_per_site = results3[i]\n",
    "#     theoretical = expected_number_subs(pi, Q_matrix, 1)\n",
    "#     t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "#     WTS_repeats_result3[repeats[i]] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'p_value': p_value, 't_stat': t_stat}\n",
    "\n",
    "# with open('../../../results/WTS_repeat(3).json', 'w') as outfile:\n",
    "#     json.dump(WTS_repeats_result3, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for different parameter that change the simulation result\n",
    "### Different rate matrix Q, t = 1, repeat = 100, sequence length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "length  = 1000\n",
    "t = 1\n",
    "repeat = 100\n",
    "Q = [Q_matrix, Q_matrix2, Q_matrix3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [1, 2, 3]\n",
    "results_Q_1 = []\n",
    "for element in list(zip(seed_seq, Q)):\n",
    "    seed, matrix = element\n",
    "    simulator = SeqSimulate(matrix, 1000, 100, seed, pi)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_Q_1.append(result)\n",
    "\n",
    "WTS_Q_result1 = {}\n",
    "for i in range(len(results_Q_1)):\n",
    "    ns_per_site, avg_ns_per_site = results_Q_1[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi, Q[i], 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_Q_result1[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_Q(1).json', 'w') as outfile:\n",
    "    json.dump(WTS_Q_result1, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [4, 5, 6]\n",
    "results_Q_2 = []\n",
    "for element in list(zip(seed_seq, Q)):\n",
    "    seed, matrix = element\n",
    "    simulator = SeqSimulate(matrix, 1000, 100, seed, pi)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_Q_2.append(result)\n",
    "\n",
    "WTS_Q_result2 = {}\n",
    "for i in range(len(results_Q_2)):\n",
    "    ns_per_site, avg_ns_per_site = results_Q_2[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi, Q[i], 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_Q_result2[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_Q(2).json', 'w') as outfile:\n",
    "    json.dump(WTS_Q_result2, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [7, 8, 9]\n",
    "results_Q_3 = []\n",
    "for element in list(zip(seed_seq, Q)):\n",
    "    seed, matrix = element\n",
    "    simulator = SeqSimulate(matrix, 1000, 100, seed, pi)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_Q_3.append(result)\n",
    "\n",
    "WTS_Q_result3 = {}\n",
    "for i in range(len(results_Q_3)):\n",
    "    ns_per_site, avg_ns_per_site = results_Q_3[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi, Q[i], 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_Q_result3[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_Q(3).json', 'w') as outfile:\n",
    "    json.dump(WTS_Q_result3, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different pi, length = 1000, repeat = 100, t = 1, Q = Q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "length  = 1000\n",
    "t = 1\n",
    "repeat = 100\n",
    "pi_list = [pi, pi2, pi3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [1, 2, 3]\n",
    "results_pi_1 = []\n",
    "for element in list(zip(seed_seq, pi_list)):\n",
    "    seed, pi_element = element\n",
    "    simulator = SeqSimulate(Q_matrix, 1000, 100, seed, pi_element)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_pi_1.append(result)\n",
    "\n",
    "WTS_pi_result1 = {}\n",
    "for i in range(len(results_pi_1)):\n",
    "    ns_per_site, avg_ns_per_site = results_pi_1[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi_list[i], Q_matrix, 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_pi_result1[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_pi(1).json', 'w') as outfile:\n",
    "    json.dump(WTS_pi_result1, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [4, 5, 6]\n",
    "results_pi_2 = []\n",
    "for element in list(zip(seed_seq, pi_list)):\n",
    "    seed, pi_element = element\n",
    "    simulator = SeqSimulate(Q_matrix, 1000, 100, seed, pi_element)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_pi_2.append(result)\n",
    "\n",
    "WTS_pi_result2 = {}\n",
    "for i in range(len(results_pi_2)):\n",
    "    ns_per_site, avg_ns_per_site = results_pi_2[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi_list[i], Q_matrix, 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_pi_result2[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_pi(2).json', 'w') as outfile:\n",
    "    json.dump(WTS_pi_result2, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_seq = [7, 8, 9]\n",
    "results_pi_3 = []\n",
    "for element in list(zip(seed_seq, pi_list)):\n",
    "    seed, pi_element = element\n",
    "    simulator = SeqSimulate(Q_matrix, 1000, 100, seed, pi_element)\n",
    "    result = simulator.average_substitution(max_time = 1)\n",
    "    results_pi_3.append(result)\n",
    "\n",
    "WTS_pi_result3 = {}\n",
    "for i in range(len(results_pi_3)):\n",
    "    ns_per_site, avg_ns_per_site = results_pi_3[i]\n",
    "    std = np.std(ns_per_site)\n",
    "    cv = std/avg_ns_per_site\n",
    "    theoretical = expected_number_subs(pi_list[i], Q_matrix, 1)\n",
    "    error_list = [a - theoretical for a in ns_per_site]\n",
    "    t_stat, p_value = stats.ttest_1samp(ns_per_site, theoretical)\n",
    "    WTS_pi_result3[i] = {'ns_per_site_list': ns_per_site, 'avg_ns_per_site': avg_ns_per_site, 'theoretical_value': theoretical, 'error': error_list, 'p_value': p_value, 't_stat': t_stat, 'cv': cv, 'std': std}\n",
    "\n",
    "with open('../../../results/WTS_pi(3).json', 'w') as outfile:\n",
    "    json.dump(WTS_pi_result3, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
